{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importar los archivos del proyecto"
      ],
      "metadata": {
        "id": "oze_aba4-9Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "qpxdPTuM80Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opción 1: Traer sólo los módulos con las clases:"
      ],
      "metadata": {
        "id": "qMNIimja_BbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_module(url):\n",
        "    fname = url.split('/')[-1]\n",
        "    r = requests.get(url)\n",
        "    with open(fname, 'w') as f:\n",
        "        f.write(r.text)"
      ],
      "metadata": {
        "id": "icR_OdBg7UOk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\"https://raw.githubusercontent.com/gmauricio-toledo/SA-paper/master/experiment_tools_SA.py\",\n",
        "        \"https://raw.githubusercontent.com/gmauricio-toledo/SA-paper/master/scoring.py\",\n",
        "        \"https://raw.githubusercontent.com/gmauricio-toledo/SA-paper/master/SentimentKW.py\",\n",
        "        \"https://raw.githubusercontent.com/gmauricio-toledo/SA-paper/master/TextCleaner.py\",\n",
        "        \"https://raw.githubusercontent.com/gmauricio-toledo/SA-paper/master/TextRank.py\"\n",
        "        ]\n",
        "\n",
        "for url in urls:\n",
        "    get_module(url)"
      ],
      "metadata": {
        "id": "fsnmHWoxLEgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opción 2: Traer todo el repositorio github en el root"
      ],
      "metadata": {
        "id": "iC5Anj1l_IX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git init\n",
        "!git pull https://github.com/gmauricio-toledo/SA-paper.git "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qYo2pV_-NkZ",
        "outputId": "1ced69d2-9b0f-4181-c08e-005e4031d0e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "enS918h2CvvF",
        "outputId": "96bf23aa-9374-432b-bfd8-ea0a87e27abc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gensim"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "U7G5FSJG_ZNh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8uNktOhJJkRY"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from scoring import Scoring\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h5f3lhaJkR_"
      },
      "source": [
        "## Single run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4vnl9a4KJkSB",
        "outputId": "820e7901-9b6a-4e1e-b457-e0d77d1ce68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Llave  Paciente  Sexo  cal_vida  \\\n",
              "3773  16019      7959     1      46.6   \n",
              "4827  18118     11770     1      68.0   \n",
              "4186  16810      9282     1      65.2   \n",
              "\n",
              "                                                  Texto  ds03  ds45  dp0  dp1  \\\n",
              "3773  sigo soñando muchas personas cada vez definida...     0     1    1  0.0   \n",
              "4827  semana bastante estresante pensando jueves cit...     0     1    1  0.0   \n",
              "4186  hoy ido excursión unas amigas agencia arawak v...     0     1    0  1.0   \n",
              "\n",
              "      ds0  ds1  ds2  ds3  ds4  ds5  ds   dp  \n",
              "3773    0    0    0    0    0    1   5  0.0  \n",
              "4827    0    0    0    0    0    1   5  0.0  \n",
              "4186    0    0    0    0    1    0   4  1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47b86ca7-e2a5-473c-abce-831446a13f00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Llave</th>\n",
              "      <th>Paciente</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>cal_vida</th>\n",
              "      <th>Texto</th>\n",
              "      <th>ds03</th>\n",
              "      <th>ds45</th>\n",
              "      <th>dp0</th>\n",
              "      <th>dp1</th>\n",
              "      <th>ds0</th>\n",
              "      <th>ds1</th>\n",
              "      <th>ds2</th>\n",
              "      <th>ds3</th>\n",
              "      <th>ds4</th>\n",
              "      <th>ds5</th>\n",
              "      <th>ds</th>\n",
              "      <th>dp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3773</th>\n",
              "      <td>16019</td>\n",
              "      <td>7959</td>\n",
              "      <td>1</td>\n",
              "      <td>46.6</td>\n",
              "      <td>sigo soñando muchas personas cada vez definida...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4827</th>\n",
              "      <td>18118</td>\n",
              "      <td>11770</td>\n",
              "      <td>1</td>\n",
              "      <td>68.0</td>\n",
              "      <td>semana bastante estresante pensando jueves cit...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4186</th>\n",
              "      <td>16810</td>\n",
              "      <td>9282</td>\n",
              "      <td>1</td>\n",
              "      <td>65.2</td>\n",
              "      <td>hoy ido excursión unas amigas agencia arawak v...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47b86ca7-e2a5-473c-abce-831446a13f00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47b86ca7-e2a5-473c-abce-831446a13f00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47b86ca7-e2a5-473c-abce-831446a13f00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_model = Word2Vec.load(\"data/word2vec.model\")\n",
        "\n",
        "# ---- Leemos los mensajes ----\n",
        "msjs_df = pd.read_csv(\"data/sms_full_dataframe.csv\",index_col=0)\n",
        "# msjs_df['Normalized Label'] = (2/5)*msjs_df['ds'].values-1\n",
        "# y = msjs_df['ds'].values\n",
        "\n",
        "msjs_df.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gyBY6_pfJkSD",
        "outputId": "44d12ba1-12f5-41b4-f023-8bd043920a2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe contains entries with 6 labels:\n",
            "[0 1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "from experiment_tools_SA import SentimentAnalysis\n",
        "\n",
        "\n",
        "# betas1 = [0.5,1,2]#np.linspace(0.1,2,5)\n",
        "# betas2 = [0.5,1,2]#np.linspace(0.5,5,5)\n",
        "# nums_cols = [3,5,7]\n",
        "# alphas = [0.5,0.75,0.9]#np.linspace(0.25,0.98,5)\n",
        "\n",
        "# params_dict = {\n",
        "#                 # 'beta1':betas1,\n",
        "#                 # 'beta2':betas2,\n",
        "#                 'n_cols':nums_cols\n",
        "#                 # 'alpha':alphas\n",
        "#                 }\n",
        "\n",
        "\n",
        "\n",
        "hpd = {'emb_model': w2v_model}\n",
        "\n",
        "sa = SentimentAnalysis(hyper_params_dict=hpd,\n",
        "                        df=msjs_df,\n",
        "                        text_col_name='Texto',\n",
        "                        label_col_name='ds',\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qVV9BFgNJkSF",
        "outputId": "799a24ba-b974-4b6d-c001-bc6a9f0add0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando palabras prototípicas... done in 381.64676\n",
            "Construyendo vecinos... done in 337.2408\n",
            "Calculando puntajes... done in 8.02782\n",
            "Calculando representaciones... done in 5.04637\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 1.3738 - accuracy: 0.5237\n",
            "done in 27.65698\n",
            "Iteración 1/3 completada.\n",
            "Construyendo vecinos... done in 735.70558\n",
            "Calculando puntajes... done in 8.03441\n",
            "Calculando representaciones... done in 4.92504\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 1.2090 - accuracy: 0.5666\n",
            "done in 33.54966\n",
            "Iteración 2/3 completada.\n",
            "Construyendo vecinos... done in 736.01638\n",
            "Calculando puntajes... done in 8.07116\n",
            "Calculando representaciones... done in 5.15763\n",
            "43/43 [==============================] - 0s 9ms/step - loss: 1.2867 - accuracy: 0.5470\n",
            "done in 32.50956\n",
            "Iteración 3/3 completada.\n"
          ]
        }
      ],
      "source": [
        "comb_dict = {\n",
        "            'beta1': 1,\n",
        "            'beta2': 5,\n",
        "            'n_cols': 9,\n",
        "            'alpha': 0.9,\n",
        "            'top_n': 100,\n",
        "            'n_iter': 3\n",
        "            }\n",
        "\n",
        "results = sa.run(combination_dict=comb_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dme77OceJkSH",
        "outputId": "86fd36ff-49dd-4014-e2d1-a56207d779d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'test_loss': 1.286723256111145, 'test_accuracy': 0.5469774007797241, 'predictions': array([5, 5, 5, ..., 5, 5, 0])}\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrivu3CMJkSI"
      },
      "source": [
        "## Gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsS2MU2CJkSJ",
        "outputId": "175dc9c1-68b9-48f7-c5df-bc36d1ee2094"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Llave</th>\n",
              "      <th>Paciente</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>cal_vida</th>\n",
              "      <th>Texto</th>\n",
              "      <th>ds03</th>\n",
              "      <th>ds45</th>\n",
              "      <th>dp0</th>\n",
              "      <th>dp1</th>\n",
              "      <th>ds0</th>\n",
              "      <th>ds1</th>\n",
              "      <th>ds2</th>\n",
              "      <th>ds3</th>\n",
              "      <th>ds4</th>\n",
              "      <th>ds5</th>\n",
              "      <th>ds</th>\n",
              "      <th>dp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>898</td>\n",
              "      <td>182</td>\n",
              "      <td>2</td>\n",
              "      <td>44.6</td>\n",
              "      <td>nota apuntada si hijo consigue quiere quiere f...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2510</th>\n",
              "      <td>12933</td>\n",
              "      <td>5230</td>\n",
              "      <td>1</td>\n",
              "      <td>21.4</td>\n",
              "      <td>levanto cansada bastantes dolores espalda braz...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1119</th>\n",
              "      <td>7105</td>\n",
              "      <td>2305</td>\n",
              "      <td>2</td>\n",
              "      <td>2.2</td>\n",
              "      <td>cansado torpe hoy caído calle puede ser cada v...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Llave  Paciente  Sexo  cal_vida  \\\n",
              "214     898       182     2      44.6   \n",
              "2510  12933      5230     1      21.4   \n",
              "1119   7105      2305     2       2.2   \n",
              "\n",
              "                                                  Texto  ds03  ds45  dp0  dp1  \\\n",
              "214   nota apuntada si hijo consigue quiere quiere f...     1     0    0  1.0   \n",
              "2510  levanto cansada bastantes dolores espalda braz...     0     1    1  0.0   \n",
              "1119  cansado torpe hoy caído calle puede ser cada v...     1     0    0  1.0   \n",
              "\n",
              "      ds0  ds1  ds2  ds3  ds4  ds5  ds   dp  \n",
              "214     0    1    0    0    0    0   1  1.0  \n",
              "2510    0    0    0    0    0    1   5  0.0  \n",
              "1119    1    0    0    0    0    0   0  1.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe contains entries with 6 labels:\n",
            "[0 1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "from experiment_tools_SA import SentimentAnalysis\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_model = Word2Vec.load(\"data/word2vec.model\")\n",
        "\n",
        "# ---- Leemos los mensajes ----\n",
        "msjs_df = pd.read_csv(\"data/sms_full_dataframe.csv\",index_col=0)\n",
        "# msjs_df['Normalized Label'] = (2/5)*msjs_df['ds'].values-1\n",
        "# y = msjs_df['ds'].values\n",
        "\n",
        "display(msjs_df.sample(3))\n",
        "\n",
        "hpd = {'emb_model': w2v_model}\n",
        "\n",
        "sa = SentimentAnalysis(hyper_params_dict=hpd,\n",
        "                        df=msjs_df,\n",
        "                        text_col_name='Texto',\n",
        "                        label_col_name='ds',\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBAzQI5JJkSK"
      },
      "outputs": [],
      "source": [
        "betas1 = [0.5,1]#np.linspace(0.1,2,5)\n",
        "betas2 = [1,2]#np.linspace(0.5,5,5)\n",
        "nums_cols = [3,7]\n",
        "alphas = [0.9]#np.linspace(0.25,0.98,5)\n",
        "\n",
        "params_dict = {\n",
        "                'beta1':betas1,\n",
        "                'beta2':betas2,\n",
        "                'n_cols':nums_cols,\n",
        "                'alpha':alphas\n",
        "                }\n",
        "\n",
        "\n",
        "dpd = {\n",
        "                'beta1': 1,\n",
        "                'beta2': 1,\n",
        "                'n_cols': 5,\n",
        "                'alpha': 0.5,\n",
        "                'top_n': 50,\n",
        "                'n_iter': 3\n",
        "                }\n",
        "\n",
        "sa.grid_search(param_dict=params_dict,\n",
        "                default_params_dict=dpd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joKfj_LWJkSN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modificar la clase "
      ],
      "metadata": {
        "id": "X-kRgJtvWwax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "# import seaborn as sns\n",
        "from operator import itemgetter\n",
        "from math import exp, log\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "\n",
        "class Scoring:\n",
        "\n",
        "    def __init__(self,w2vmodel,W0:dict):\n",
        "        self.W0 = W0\n",
        "        self.model = w2vmodel\n",
        "        self.vocab = list(w2vmodel.wv.key_to_index.keys())\n",
        "        # Estas variables controlan el flujo y orden de los métodos:\n",
        "        self.W0_check = False\n",
        "        self.words_rep_check = False\n",
        "        self.texts_rep_check = False\n",
        "        self.scoring_check = False\n",
        "        self.kv = False # Indica si el módelo son keyedvectors\n",
        "    \n",
        "    def build_neighbors(self,alpha=0):\n",
        "        '''\n",
        "        Esta función regresa un diccionario indexado con los vecinos más cercanos de la lista\n",
        "        de palabras prototípicas W0_list. El valor del vecino es una tupla (max_sim,word_sim) donde\n",
        "        max_sim: similitud con el vecino más cercano en W0_list\n",
        "        word_sim: el vecino más cercano en W0_list\n",
        "        '''\n",
        "        model = self.model\n",
        "        self.alpha = alpha\n",
        "        W0_list = list(self.W0.keys())\n",
        "        vecinos_W0 = {}\n",
        "        N = len(self.vocab)\n",
        "        filtered_W0 = [w for w in W0_list if w in self.vocab]\n",
        "        for w in filtered_W0:\n",
        "            vecinos_full = model.wv.similar_by_word(w,topn=N) \n",
        "            vecinos = []\n",
        "            for pair in vecinos_full:\n",
        "                if pair[1]>self.alpha:\n",
        "                    vecinos.append(pair)\n",
        "                else:\n",
        "                    break\n",
        "            # vecinos = [pair for pair in vecinos_full if pair[1]>self.alpha] \n",
        "            for pair in vecinos:\n",
        "                if pair[0] not in W0_list:\n",
        "                    if pair[0] in vecinos_W0.keys():\n",
        "                        vecinos_W0[pair[0]].append((pair[1],w))\n",
        "                    else:\n",
        "                        vecinos_W0[pair[0]] = [(pair[1],w)]\n",
        "        vecinos_W0 = {word:max(vecinos_W0[word],key=itemgetter(0)) for word in vecinos_W0.keys()}\n",
        "        self.vecinos = vecinos_W0\n",
        "        self.W0_check = True\n",
        "\n",
        "        # implementar la nueva forma:\n",
        "        \n",
        "\n",
        "    def __s_tilde(self,label:int,word:str):\n",
        "        '''\n",
        "        Esta función devuelve el pre-scoring de una palabra <word> en un mensaje con tag ds, la cual está normalizado entre -1 y 1.\n",
        "        El diccionario <W0> contiene la lista de las palabras prototípicas como llaves y sus\n",
        "        respectivos scores como values.\n",
        "        El diccionario <W0_vecinos> contiene la lista de vecinos más cercanos a las palabras prototípicas \n",
        "        de W0 como llaves, los valores son tuplas (sim,vec) donde <vec> es el vecino más cercano\n",
        "        en las palabras prototípicas y <sim> es la similitud que tiene con este vecino\n",
        "        '''\n",
        "        beta1,beta2 = self.beta1,self.beta2\n",
        "        W0 = self.W0\n",
        "        W0_vecinos = self.vecinos\n",
        "        if word in self.vocab:\n",
        "            pre_score = 0\n",
        "            if word in W0.keys():\n",
        "                check = label*W0[word]\n",
        "                if check >= 0:\n",
        "                    pre_score = np.tanh(beta1*(label + W0[word]))\n",
        "                if check < 0:\n",
        "                    x = label - W0[word]\n",
        "                    if x <= 0:\n",
        "                        pre_score = exp(beta2*x)\n",
        "                    else: \n",
        "                        pre_score = -exp(-beta2*x)\n",
        "            elif word in W0_vecinos.keys():\n",
        "                check = label*W0[W0_vecinos[word][1]]\n",
        "                if check >= 0:\n",
        "                    pre_score = np.tanh(beta1*(label + (W0_vecinos[word][0]*W0[W0_vecinos[word][1]])))\n",
        "                if check < 0:\n",
        "                    x = label - (W0_vecinos[word][0]*W0[W0_vecinos[word][1]])\n",
        "                    if x <= 0:\n",
        "                        pre_score = exp(beta2*x)\n",
        "                    else: \n",
        "                        pre_score = -exp(-beta2*x)\n",
        "            return pre_score \n",
        "\n",
        "    def __count_freq(self):\n",
        "        freqs = {w:0 for w in self.vocab}\n",
        "        for j in self.data_df.index.to_list():\n",
        "            BOW = self.data_df.iloc[j,0]\n",
        "            for word in BOW.split():\n",
        "                try:\n",
        "                    freqs[word] += 1\n",
        "                except:\n",
        "                    pass\n",
        "        return freqs\n",
        "\n",
        "    def transform(self,df,beta1=1,beta2=1,text_col=\"text\",label_col=\"label\"):\n",
        "        if self.W0_check:\n",
        "            self.beta1 = beta1\n",
        "            self.beta2 = beta2\n",
        "            self.data_df = df[[text_col,label_col]].copy()\n",
        "            self.data_df.rename(columns={text_col:\"text\",label_col:\"label\"},inplace=True)  # Estandarizar el nombre de las columnas del dataframe interno\n",
        "            self.frequencies = self.__count_freq()\n",
        "            y = self.data_df[\"label\"].values\n",
        "            self.n_classes = np.unique(y).shape[0]\n",
        "            scoring = {w:0 for w in self.vocab} \n",
        "            #--- Acumulamos los scores:\n",
        "            for j,k in enumerate(self.data_df.index.to_list()): \n",
        "                BOW = self.data_df.loc[k,\"text\"]\n",
        "                BOW = [x for x in BOW.split() if x in self.vocab]\n",
        "                for w in BOW:\n",
        "                    scoring[w] += self.__s_tilde(y[j],w)\n",
        "            #--- Normalizamos dividiendo entre la frecuencia:\n",
        "            for w in scoring.keys():\n",
        "                if self.frequencies[w]!=0:\n",
        "                    scoring[w] = scoring[w]/self.frequencies[w]\n",
        "                else:\n",
        "                    scoring[w] = 0\n",
        "            self.scoring = scoring\n",
        "            #--- Construir el dataframe\n",
        "            data = {'word':[w for w in self.vocab],\n",
        "                    'score':[scoring[w] for w in self.vocab]\n",
        "                    }\n",
        "            scores_df = pd.DataFrame(data)\n",
        "            self.scoring_check = True\n",
        "            return scores_df\n",
        "        else:\n",
        "            self.build_neighbors()\n",
        "            self.W0_check = True\n",
        "            print(\"No se habían construido los vecinos más cercanos. Volver a ejecutar 'transform'.\")\n",
        "    \n",
        "    def get_t_score(self):\n",
        "        pass\n",
        "\n",
        "    def change_model(self,new_model,kv='False'):\n",
        "        self.model = new_model\n",
        "        if kv:\n",
        "            self.kv = True\n",
        "\n",
        "    def get_words_representations(self,mode='mean'):\n",
        "        '''\n",
        "        Esta función regresa las representaciones de las palabras como re-escalamientos por el score de cada palabra. Hay varios modos:\n",
        "        'mean': La representación de cada palabra es el promedio pesado de los pre-puntajes en cada etiqueta.\n",
        "        '''\n",
        "        if self.scoring_check and self.W0_check:\n",
        "            N = len(self.vocab)\n",
        "            n_dim = self.model.vector_size\n",
        "            if self.kv:\n",
        "                kv = self.model\n",
        "            else:\n",
        "                kv = self.model.wv\n",
        "            X_word_rep = np.zeros(shape=(N,n_dim))\n",
        "            for k,word in enumerate(self.vocab):\n",
        "                try:\n",
        "                    X_word_rep[k,:] = self.scoring[word]*kv.get_vector(word,norm=True) \n",
        "                    # X_word_rep[k,:] = self.scoring[word]*self.model.wv.get_vector(word,norm=True)\n",
        "                except:\n",
        "                    pass \n",
        "            self.word_reps = X_word_rep\n",
        "            self.words_rep_check = True\n",
        "            return X_word_rep\n",
        "        else:\n",
        "            print(\"No se ha ejecutado 'build_neighbors' o 'transform'.\")\n",
        "        \n",
        "    def get_texts_representations_mean(self):\n",
        "        '''\n",
        "        Este método obtiene las representaciones de los textos, cada una es un vector, el cual es el promedio de las representaciones\n",
        "        de las palabras que lo componen\n",
        "        '''\n",
        "        n_dim = self.model.vector_size\n",
        "        if self.words_rep_check:\n",
        "            X_word_rep = self.word_reps\n",
        "        else:\n",
        "            X_word_rep = self.get_words_representations()\n",
        "        M = self.data_df.shape[0]\n",
        "        X_msj_rep = np.zeros(shape=(M,n_dim))\n",
        "        for k in self.data_df.index.to_list():\n",
        "            rep_msj = np.zeros(shape=(n_dim,))\n",
        "            BOW = self.data_df.loc[k,'text']\n",
        "            BOW = [x for x in BOW.split() if x in self.vocab]\n",
        "            for word in BOW:\n",
        "                idx = self.vocab.index(word)\n",
        "                rep_msj += X_word_rep[idx]\n",
        "            rep_msj = rep_msj/len(BOW)\n",
        "            X_msj_rep[k] = rep_msj\n",
        "        self.text_rep = X_msj_rep\n",
        "        return X_msj_rep\n",
        "\n",
        "    def get_texts_representations_Nmean(self,n=3):\n",
        "        '''\n",
        "        'partial-mean': Lo mismo que <get_texts_representations_mean>, pero sólo se promedian las <n> palabras con score más alto, en valor absoluto.\n",
        "        '''\n",
        "        n_dim = self.model.vector_size\n",
        "        if self.words_rep_check:\n",
        "            X_word_rep = self.word_reps\n",
        "        else:\n",
        "            X_word_rep = self.get_words_representations()\n",
        "        M = self.data_df.shape[0]\n",
        "        X_msj_rep = np.zeros(shape=(M,n_dim))\n",
        "        for k in self.data_df.index.to_list():\n",
        "            mat_rep = np.zeros(shape=(n,n_dim))  # Matriz con las <n> representaciones vectoriales de las palabras, las más grandes en val. abs.\n",
        "            BOW = self.data_df.loc[k,'text'].split()\n",
        "            words_scores = [(word,self.scoring[word]) for word in BOW if word in self.vocab] # Juntamos los scores de cada palabra del msj\n",
        "            non_zero_scores = [x for x in words_scores if x[1]!=0] # Sólo nos quedamos con las palabras del mensaje con pre-score diferente de 0\n",
        "            size = len(non_zero_scores) \n",
        "            lista = [(x[0],abs(x[1])) for x in non_zero_scores] # Construimos una nueva lista con el valor abs de cada score y su idx en la lista original\n",
        "            sorted_non_zero_scores = sorted(lista,key=itemgetter(1), reverse=True) # Ordenamos los valores absolutos de los scores de las palabras que forman el msj\n",
        "            for i in range(min(n,size)):\n",
        "                word_idx = self.vocab.index(sorted_non_zero_scores[i][0])\n",
        "                mat_rep[i,:] = X_word_rep[word_idx]\n",
        "            X_msj_rep[k,:] = np.mean(mat_rep,axis=0)\n",
        "        self.text_rep = X_msj_rep\n",
        "        return X_msj_rep\n",
        "\n",
        "    def get_texts_representations_Wmean(self,weights):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def get_texts_representations_MAT(self,cols_num=1):\n",
        "        '''\n",
        "        Esta función obtiene las representaciones de los mensajes, cada una de las cuales es una matriz conteniendo los k vectores (palabras)\n",
        "        con el mayor pre-score, ya sea en valor absoluto o que conincidan con la polaridad del mensaje.\n",
        "        <cols_num>: La cantidad de columnas que contiene la representación del mensaje\n",
        "        El tensor que regresa es de tamaño (msg_num,100,cols_num)\n",
        "        '''\n",
        "        M = self.data_df.shape[0]\n",
        "        n_dim = self.model.vector_size\n",
        "        if self.kv:\n",
        "            kv = self.model\n",
        "        else:\n",
        "            kv = self.model.wv\n",
        "        X_msj_rep = np.zeros(shape=(cols_num,M,n_dim))\n",
        "        for k in self.data_df.index.to_list():\n",
        "            BOW = self.data_df.loc[k,\"text\"].split()\n",
        "            BOW = [w for w in BOW if w in self.vocab]\n",
        "            words_scores = [(word,self.scoring[word]) for word in BOW] # Juntamos los scores de cada palabra del msj\n",
        "            non_zero_scores = [x for x in words_scores if x[1]!=0] # Sólo nos quedamos con las palabras del mensaje con pre-score diferente de 0\n",
        "            size = len(non_zero_scores) \n",
        "            lista = [(x[0],abs(x[1]),j) for j,x in enumerate(non_zero_scores)] # Construimos una nueva lista con el valor abs de cada pre-score y su idx en la lista original\n",
        "            sorted_non_zero_scores = sorted(lista,key=itemgetter(1), reverse=True) # Ordenamos los valores absolutos de los pre-scores de las palabras que forman el msj\n",
        "            A_m = np.zeros(shape=(n_dim,size)) # La matriz que contendrá como columnas las representaciones de las palabras\n",
        "            if size>1:  # Si tiene más de una palabra con prescore distinto de 0, escogemos las mayores\n",
        "                for j,triplet in enumerate(sorted_non_zero_scores):\n",
        "                    try:\n",
        "                        A_m[:,j] = non_zero_scores[triplet[2]][1]*kv.get_vector(non_zero_scores[triplet[2]][0],norm=True)\n",
        "                    except:\n",
        "                        pass\n",
        "                if size>=cols_num:\n",
        "                    A_m = A_m[:,:cols_num].copy() # Sólo nos quedamos con las primeras <cols_num> columnas\n",
        "                    X_msj_rep[:,k,:] = A_m.reshape((A_m.shape[1],A_m.shape[0]))\n",
        "                else:\n",
        "                    X_msj_rep[:size,k,:] = A_m.reshape((A_m.shape[1],A_m.shape[0]))\n",
        "            elif size==1: # Si sólo hay una palabra con prescore distinto de 0, esa es la representación del mensaje\n",
        "                pair = non_zero_scores[0]\n",
        "                try:\n",
        "                    X_msj_rep[0,k,:] = pair[1]*kv.get_vector(pair[0],norm=True)  \n",
        "                except:\n",
        "                    pass\n",
        "        if cols_num==1:\n",
        "            X_msj_rep = X_msj_rep.reshape(M,n_dim)\n",
        "        X_msj_rep = np.swapaxes(np.swapaxes(X_msj_rep,0,2),0,1)\n",
        "        self.text_rep = X_msj_rep\n",
        "        return X_msj_rep\n",
        "\n",
        "    def get_texts_representations_PCA(self):\n",
        "        '''\n",
        "        Esta función obtiene las representaciones de los mensajes usando PCA en la matriz de representaciones de las palabras\n",
        "        presentes en cada mensaje, las representaciones de las palabras es obtenida usando el score de cada palabra \n",
        "        '''\n",
        "        N = len(self.vocab)\n",
        "        n_dim = self.model.vector_size\n",
        "        if self.words_rep_check:\n",
        "            X_word_rep = self.word_reps\n",
        "        else:\n",
        "            X_word_rep = self.get_words_representations()\n",
        "        M = self.data_df.shape[0]\n",
        "        X_msj_rep = np.zeros(shape=(M,n_dim))\n",
        "        for k in self.data_df.index.to_list():\n",
        "            BOW = self.data_df.loc[k,'text']\n",
        "            BOW = [x for x in BOW.split() if x in self.vocab]\n",
        "            A_m = np.zeros(shape=(n_dim,len(BOW)))\n",
        "            for j,word in enumerate(BOW):\n",
        "                idx = self.vocab.index(word)\n",
        "                A_m[:,j] = X_word_rep[idx,:]\n",
        "            pca = PCA(svd_solver='auto')\n",
        "            A_m_pca = pca.fit_transform(A_m)\n",
        "            X_msj_rep[k,:] = A_m_pca[:,0].copy()\n",
        "        self.text_rep = X_msj_rep\n",
        "        return X_msj_rep\n",
        "    \n",
        "    def plot_pca_texts_rep(self,img_label:str,save=False):\n",
        "        '''\n",
        "        Esta función grafica las representaciones vectoriales de los mensajes usando PCA como reducción de dimensionalidad.\n",
        "        Cada etiqueta se representa con un color diferente. AVERIGUAR COMO REGRESAR LOS AXIS\n",
        "        '''\n",
        "        pca = PCA(svd_solver='auto')\n",
        "        A_msj_pca = pca.fit_transform(self.text_rep)\n",
        "        A_msj_pca_df = pd.DataFrame(A_msj_pca)\n",
        "        labels = np.unique(self.data_df[\"label\"].values)\n",
        "        label_idxs = [self.data_df[self.data_df['label']==j].index.to_list() for j in labels]\n",
        "        plt.figure(figsize=(7,5),dpi=500)\n",
        "        title = \"Representaciones de mensajes\\n\"+img_label\n",
        "        plt.suptitle(title)\n",
        "        for tag in labels:\n",
        "            plt.scatter(x = A_msj_pca_df.loc[label_idxs[int(tag)],0], y = A_msj_pca_df.loc[label_idxs[int(tag)],1],alpha=0.5,\n",
        "                        label=tag) \n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.legend(loc='best')\n",
        "        plt.axis(\"off\")\n",
        "        if save:\n",
        "            fname = 'IMAGES/'+img_label+'texts-representations-PCA.png'\n",
        "            plt.savefig(fname,dpi=500)\n",
        "        plt.show()\n",
        "    \n",
        "    def plot_pca_words_rep(self,img_label:str,save=False):\n",
        "        '''\n",
        "        Esta función grafica las representaciones vectoriales de las palabras usando PCA como reducción de dimensionalidad.\n",
        "        El color representa el score de la palabra\n",
        "        '''\n",
        "        if self.words_rep_check:\n",
        "            scores = list(self.scoring.values())\n",
        "            pca = PCA(svd_solver='auto')\n",
        "            X_pca = pca.fit_transform(self.word_reps)\n",
        "            X_pca_df = pd.DataFrame(X_pca)\n",
        "            plt.figure(figsize=(7,5),dpi=500)\n",
        "            title = \"Representaciones de palabras\\n\"+img_label\n",
        "            plt.suptitle(title)\n",
        "            plt.scatter(x = X_pca_df[0].values, y = X_pca_df[1].values,alpha=0.75,\n",
        "                        c = scores, cmap= 'RdBu') \n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.colorbar(orientation=\"horizontal\")\n",
        "            plt.axis(\"off\")\n",
        "            if save:\n",
        "                fname = 'IMAGES/'+img_label+'word-representations-PCA.png'\n",
        "                plt.savefig(fname,dpi=500)\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"Correr primero <get_words_representations()>\")\n",
        "\n",
        "    def save_neighbors(self,fname):\n",
        "        if self.W0_check:\n",
        "            with open(fname, 'wb') as handle:\n",
        "                pickle.dump(self.vecinos, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "            print(\"Neighbors dictionary saved.\")\n",
        "        else:\n",
        "            print(\"Neighbors have not been calculated. Try <build_neighbors> first\")\n",
        "\n",
        "    def load_neighbors(self,fname):\n",
        "        with open(fname, 'rb') as handle:\n",
        "            self.vecinos = pickle.load(handle)\n",
        "        self.W0_check = True\n",
        "\n",
        "    def save_scoring(self,fname):\n",
        "        if self.scoring_check:\n",
        "            data = {'word':list(self.scoring.keys()),\n",
        "                    'score':list(self.scoring.values())\n",
        "                    }\n",
        "            scoring_df = pd.DataFrame(data=data,columns=['word','score'])\n",
        "            filename = fname + \".csv\"\n",
        "            scoring_df.to_csv(filename)\n",
        "        else:\n",
        "            print(\"Scoring has not been calculated. Try <transform> first.\")\n",
        "\n",
        "    def load_scoring(self,fname):\n",
        "        scoring_df = pd.read_csv(fname,index_col=0)\n",
        "        self.scoring = {scoring_df.loc[j,'word']:scoring_df.loc[j,'score'] for j in scoring_df.index.to_list()}\n",
        "        self.scoring_check = True\n",
        "        self.W0_check = True"
      ],
      "metadata": {
        "id": "wMTYHXeaWvwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kgjDLHYpZBxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}